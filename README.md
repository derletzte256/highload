# Twitch
## 1. Тема и целевая аудитория
**Тема** - стриминговый сервис
### Функционал MVP:
- Регистрация/авторизация
- Создание стрима (включая установление соединение для стриминга видео)
- Просмотр стрима (включая стриминг видео)
- Подписка
- Чат в прямом эфире
- VOD (временное сохранение записи стрима)
- Создание клипов/хайлайтов стрима
- Просмотр клипов/хайлайтов и VOD

### Ключевые продуктовые решения
- При стриминге и при просмотре стриме используется один и тот же аккаунт
- Временное хранение записей трансляций для всех пользователей при активации соотвествущей функции (от 7 для простых пользователей до 2 месяцев для партнерских каналов) [^1]
- При просмотре записи есть реплей чата (повторение чата, как это было на стриме)
- Поддержка рекомендаций на основе каналов в подписках и текущего просматриваемого стрима

### Целевая аудитория
#### Метрики
- 240M MAU [^2]
- 35M DAU [^2]
- Стреднее количество одновременных зрителей в августе 2025 - 2М [^3]
- Количество часов просмотра в августе 2025 - 1498М [^3]
- Количество стримеров в августе 2025 - 7М [^3]
- Среднее количество одновременных стримов за август 2025 - 89K [^3]
- Процент пользователей мобильных устройств - 35% [^4]

#### Распределение аудитории по возрасту
- 52% - 25-34 лет [^5]
- 22% - 35-44 лет [^5]

#### Распределение аудитории по полу
- 72.26% - мужчины [^5]
- 27.74% - женщины [^5]

#### Распределение аудитории по Странам
Только десктоп пользователи за май 2025 [^6]

|  Страна | % пользователей |
| ------- | --------------- |
| США     | 23.6          |
| Россия | 9.79 |
| Германия | 8.69 |
| Франция | 6.53 |
| Испания | 4.08 |
| Остальные | 47.24 |

## 2. Рассчет нагрузки

### Продуктовые метрики
- 240M MAU [^2]
- 35M DAU [^2]
- 1M ежедневных стримов [^3]

#### Действия пользоватей по типам
| Тип | В день от одного пользователя | В день от всех пользователей | Примечание|
| --- | ----------------------------- | ---------------------------- | --- |
| Регистрация/авторизация | 0.15 | 500K [^7] + 5M = 5.5M | Количество логинов из 1/7 от DAU |
| Стриминг (время) | 3.6 минут* | 2.1М часов [^3] | *на DAU |
| Стриминг (количество) | 0.028* | 1М [^3] | *на DAU |
| Просмотр стрима (время) | 1.37 часов | 48M часов [^3] | из источника |
| Просмотр стрима (количество) | 0.06 | 2.1M [^3] | из источника |
| Подписка (бесплатная) | 1.2 | 60М | при допущении, что пользователь подписывается раз в неделю |
| Отправка сообщения в чат | 2 | 70M | ~800 в секунду [^8] |
| Создание VOD | 0.0142 | 500K | из расчета, что половину стримеров сохраняют стримы |
| Создание клипа | 0.142 | 5M | из рассчета, что на каждый стрим делается 5 клипов |
| Просмотр VOD/клипа | 0.28 | 10M | по аналогии, что зрителей в 2 раза больше созданного контента |

### Технические метрики

#### Занимаемое место
##### Пользователи
| Тип | Занимаемое место (одним пользователем) |
| -- | --------- |
| Аватар | 100КБ |
| Баннер | 100КБ |
| Мета-данные | ~несколько килобайт |
| Итог | ~200КБ |

##### Контент

| Тип | Занимаемое место (в общем) | Примечание |
| --- | ---------------- | ------ |
| Стримы (1) | 340 ПБ / 2 мес | Не растет, так как старые записи удаляются |
| Чат (2) | 1.2 ТБ / 2 мес | Не растет, так как старые записи удаляются |
| Клипы (3) | 55 ТБ / день | Хранятся вечно |


(1) Twitch по умолчанию устанавливает стрим в 1080p 60 FPS 6000 КБит/сек. 6000 * 60 * 60 = 2,7 ГБ за час трансляции. 2.1М * 60 (из расчета, что половину стримеров сохраняют стримы) * 2,7 Гб = 340 ПБ на два месяца (максимальная длительность стрима). \
(2) Максимальная длина сообщения на Twitch 255 символов [^9]. Используется кодировка UTF-8 => 1.1 байта на символ в смешанном тексте (в основном используется английский). 70М * 1.1 Байта * 255 = 20 Гб в день. 20 Гб * 60 = 1.2 Тб в 2 месяца, так как хранятся со стримами и удалятся вместе с ним. \
(3) Максимальная длина клина - 60 секунд [^10]. Возьмем за среднее 30 секунд и качество также в половино максимального 3000 Кбит/c. 3000 Кбит * 30 = 11 МБ для одного клипа. 11 МБ * 5M = 55 ТБ в день на всех пользователей.

### Сетевой трафик


| Тип | Пиковый RPS | Пиковый трафик (Гбит/c) |
| --- | --------- | -------------------- |
| Регистрация/авторизация | 63 | - |
| Стриминг | 34 (1) | 525 (2) |
| Просмотр стрима | 100 (1) | 8400 (3) |
| Подписка | 700 | - |
| Отправка сообщения в чат | 1000 [^8] | 0.005 |
| Создание VOD (1) | 0 | 0 |
| Создание клипа | 57 | - |
| Просмотр VOD/клипа | 115 | 41 |

(1) В RMTP выполняется 3 запроса, которые учитываются в RPS: connect, play/publish и play_done/done. То есть на одного зрителя/стримера 2 запроса. В пике на Twitch на всех стримах примерно 3М зрителей [^3]. 3 * 3M / (24 * 60 * 60) = 100 - для зрителей. Стримов в день ~= 1М, то есть 3 * 1M / (24 * 60 * 60) = 34. \
(2) 2.1М часов стримов в день. Стримеры используются в основном настройки по умолчанию в виде 6000 Кбит/c. 2.1М * (60 * 60) * 6000 Кбит/c / (24 * 60 * 60) = 525 Гбит/c \
(3) Из таблицы распределения трафика по зрителям (примерная) можно посчитать средний трафик в секунду на зрителя 2400 + 1575 + 225 + 56 + 12 ~ 4200 Кбит/с. Отсюда можем весь трафик за день на зрителей 48M часов распределить на секунды. 48М * (60 * 60) * 4200 Кбит/c / (24 * 60 * 60) = 8400 Гбит

| Разрешение | Трафик (Кбит/c) | Доля |
| --- | --------- | -------------------- |
| 1080p | 6000 | 40 |
| 720p | 4500 | 35 |
| 480p | 1500 | 15 |
| 360p | 800 | 7 |
| 240p | 400 | 3 |

(*) VOD записывается во время стрима, поэтому не требует дополнительных запросов.

## 3. Глобальная балансировка нагрузки
### Функциональное разбиение по доменам
Основную нагрузку на сервис представляет стриминг и просмотр стримов, исходя из этого трафик разделяется на RTMP сервера и обычные, обслуживающие остальные запросы.\
- contribute.live-video.net - RMTP
- twitch.tv - основной домен
- cdn.twitch.tv - CDN для статики (конкретно на Twitch используется домен не связанный с twitch.tv)
### Обоснование расположения ДЦ
|  Страна | % пользователей |
| ------- | --------------- |
| США     | 23.6          |
| Россия | 9.79 |
| Германия | 8.69 |
| Франция | 6.53 |
| Испания | 4.08 |
| Остальные | 47.24 |

Наибольшее количество пользователей из одной страны в США, поэтому там нужно несколько ДЦ.
Аналогично для Европейских стран. 

<img src="https://cdn.escharts.com/media/quick-upload/2023/01/Twitch_Languages-3780ba1adf29bb709fa81d5383cf4c81.png">
Исходя из большего процента испаноязычных зрителей, чем зрителей из Испании следует, что ~6% зрителей из Южной Америки и Мексики.

Общий RPS ~= 2050, Трафик ~= 9000 Гбит/c

| Расположение ДЦ   | Регион        |  Доля | RPS      | Гбит/с |
| ----------------- | ------------- | ----: | -------: | -----: |
| Франкфурт         | Европа        | 11.6% |      240 |   1040 |
| Ашберн, Вирджиния | США (Восток)  |  8.5% |      176 |    762 |
| Огайо             | США (Восток)  |  8.5% |      176 |    762 |
| Портленд, Орегон  | США (Запад)   |  8.5% |      176 |    762 |
| Стокгольм         | Европа        |  6.8% |      141 |    610 |
| Париж             | Европа        |  6.5% |      134 |    583 |
| Мадрид            | Европа        |  4.1% |       85 |    368 |
| Сан-Паулу         | Южная Америка |  4.0% |       83 |    359 |
| Лондон            | Европа        |  3.5% |       72 |    314 |
| Милан             | Европа        |  3.4% |       70 |    305 |
| Ирландия          | Европа        |  3.4% |       70 |    305 |
| Мумбаи            | Азия          |  3.4% |       70 |    305 |
| Сеул              | Азия          |  3.4% |       70 |    305 |
| Гонконг           | Азия          |  3.4% |       70 |    305 |
| Осака             | Азия          |  3.4% |       70 |    305 |
| Тайбэй            | Азия          |  3.4% |       70 |    305 |
| Нарита            | Азия          |  3.4% |       70 |    305 |
| Манила            | Азия          |  3.4% |       70 |    305 |
| Сингапур          | Азия          |  3.4% |       70 |    305 |
| Сидней            | Океания       |  3.4% |       70 |    305 |


*Расположение серверов взято из api twitch https://ingest.twitch.tv/ingests*

### Схема DNS балансировки
Для направления на близжайший ДЦ использует Geo DNS, так как ДЦ находятся по всему миру.
Могут возникать проблемы с RTMP соединением (stateful), так как при смене маршрута до Anycast IP трафик может перейти в другой узел, что приведет к разрыву сесии. Поэтому используется Geo DNS, который будет отдавать адрес конкретного ДЦ.
### Схема Anycast балансировки
Сервера объединяются под одним Anycast IP и по BGP направляются в близжайшую группу ДЦ. Используется для статики и не RTMP стриминга.
Географически близкие сервера объединяются под одним Anycast IP.
| Часть света          | Сервера                                                                                                                           |
| -------------------- | --------------------------------------------------------------------------------------------------------------------------------- |
| **Северная Америка** | Ашберн, Вирджиния (США); Огайо (США); Портленд, Орегон (США)                                                                      |
| **Южная Америка**    | Сан-Паулу (Бразилия)                                                                                                              |
| **Европа**           | Стокгольм (Швеция); Франкфурт (Германия); Милан (Италия); Париж (Франция); Лондон (Великобритания); Ирландия; Мадрид (Испания)    |
| **Азия**             | Мумбаи (Индия); Сеул (Республика Корея); Гонконг; Осака (Япония); Тайбэй (Тайвань); Нарита (Япония); Манила (Филиппины); Сингапур |
| **Океания**          | Сидней (Австралия)                                                                                                                |

## 4. Локальная банасировка нагрузки

### Стриминг
В качестве балансировщика используется LVS Virtual Server via Direct Routing, так как обладает наибольшей производительностью, но необходимо держать сервера в одной физической сети
В NGINX будет использоваться модуль stream, который будет распределять подключения по стратегии Least Connections.
### HTTP запросы
Обрабытваются на уровне L7 по алгоритму Least Connections

#### SSL Termination
Балансировщик на уровне L7 будет дешифровать данные и передавать по HTTP.
Так как RPS достаточно мал, SSL Termination не будет сильно влиять на производительность.
### Резервирование
На каждый ДЦ резервируется N + 1 балансировщиков относительно необходимого по трафику
### Отказоустойчивость
Используется keepalived для проверки доступности балансировщика и его замены в случае падения

### Рассчет необходимого количества балансировщиков
Допущения:
- L4 балансировщик имеет пропускную способность 100 Гбит/c (для 100GbE сетевой карты)
- одного L7 балансировщика достаточно для имеющегося RPS для обычных запросов [^11] + 1 для отказоустойчивости

| Расположение ДЦ   | Регион        | Гбит/с | N (L4) | N (L7) |
| ----------------- | ------------- | -----  | ----- | --- |
| Франкфурт         | Европа        |   1040 | 13    | 2 |
| Ашберн, Вирджиния | США (Восток)  |    762 | 9 | 2 |
| Огайо             | США (Восток)  |    762 | 9 | 2 |
| Портленд, Орегон  | США (Запад)   |    762 | 9 | 2 |
| Стокгольм         | Европа        |    610 | 8 | 2 |
| Париж             | Европа        |    583 | 7 | 2 |
| Мадрид            | Европа        |    368 | 5 | 2 |
| Сан-Паулу         | Южная Америка |    359 | 5 | 2 |
| Лондон            | Европа        |    314 | 4 | 2 |
| Милан             | Европа        |    305 | 4 | 2 |
| Ирландия          | Европа        |    305 | 4 | 2 |
| Мумбаи            | Азия          |    305 | 4 | 2 |
| Сеул              | Азия          |    305 | 4 | 2 |
| Гонконг           | Азия          |    305 | 4 | 2 |
| Осака             | Азия          |    305 | 4 | 2 |
| Тайбэй            | Азия          |    305 | 4 | 2 |
| Нарита            | Азия          |    305 | 4 | 2 |
| Манила            | Азия          |    305 | 4 | 2 |
| Сингапур          | Азия          |    305 | 4 | 2 |
| Сидней            | Океания       |    305 | 4 | 2 |

## 5. Логическая схема БД

<img width="2172" height="1454" alt="Untitled (3)" src="https://github.com/user-attachments/assets/47a78a5b-40bc-4fea-9d7f-a357ad3f35f1" />

### Размеры полей
| USER_ACCOUNT        | CHANNEL                | STREAM            | RTMP_INGEST_SESSION       | SUBSCRIPTION       | CHAT_MESSAGE      | MEDIA_OBJECT         | VOD_ASSET                | CLIP                  | SESSION            |
| ------------------- | ---------------------- | ----------------- | ------------------------- | ------------------ | ----------------- | -------------------- | ------------------------ | --------------------- | ------------------ |
| id (16 Б)           | id (16 Б)              | id (16 Б)         | id (16 Б)                 | follower_id (16 Б) | id (16 Б)         | id (16 Б)            | id (16 Б)                | id (16 Б)             | id (16 Б)          |
| email (255 Б)       | user_id (16 Б)         | channel_id (16 Б) | stream_id (16 Б)          | channel_id (16 Б)  | stream_id (16 Б)  | kind (1 Б)           | playlist_media_id (16 Б) | creator_id (16 Б)     | user_id (16 Б)     |
| username (32 Б)     | display_name (128 Б)   | title (128 Б)     | ingest_point (16 Б)       | created_at (8 Б)   | user_id (16 Б)    | storage_url (200 Б)  | stream_id (16 Б)         | stream_id (16 Б)      | created_at (8 Б)   |
| pass_hash (60 Б)    | stream_key_hash (60 Б) | status (1 Б)      | encoder_ip (16 Б)         |                    | offset_ms (8 Б)   | size_bytes (8 Б)     | playlist_media_id (16 Б) | start_ms (4 Б)        | last_seen_at (8 Б) |
| created_at (8 Б)    | is_partner (1 Б)       | started_at (8 Б)  | presented_key_hash (60 Б) |                    | content (280 Б)   | checksum (32 Б)      | duration_sec (4 Б)       | duration_ms (4 Б)     | expires_at (8 Б)   |
| last_login_at (8 Б) | avatar_media_id (16 Б) | ended_at (8 Б)    | encoder_cfg (JSON, 64 Б)  |                    | meta (JSON, 64 Б) | extra (JSON, 64 Б)   | total_size_bytes (8 Б)   | video_media_id (16 Б) |                    |
|                     | banner_media_id (16 Б) | vod_enabled (1 Б) | started_at (8 Б)          |                    | created_at (8 Б)  | created_at (8 Б)     | created_at (8 Б)         | thumb_media_id (16 Б) |                    |
|                     | created_at (8 Б)       | tags (JSON, 64 Б) | ended_at (8 Б)            |                    |                   | ttl_expires_at (8 Б) |                          | created_at (8 Б)      |                    |



| CHANNEL_COUNTERS      | STREAM_COUNTERS     | VOD_COUNTERS         | CLIP_COUNTERS     |
| --------------------- | ------------------- | -------------------- | ----------------- |
| channel_id (16 Б)     | stream_id (16 Б)    | vod_asset_id (16 Б)  | clip_id (16 Б)    |
| followers_count (8 Б) | chat_messages (8 Б) | views_total (8 Б)    | views_total (8 Б) |
| updated_at (8 Б)      | viewers (4 Б)       | watch_time_sec (8 Б) | updated_at (8 Б)  |
|                       | updated_at (8 Б)    | updated_at (8 Б)     |                   |



### Рассчеты для таблиц
| Сущность            | Вес записи | Строк/сутки (оценка) | Прирост/сутки | Примечания                                                                    |
| ------------------- | ---------: | -------------------: | ------------: | ----------------------------------------------------------------------------- |
| USER_ACCOUNT        |      379 Б |                 500К |        190 МБ | Регистрации/день (0.5M)                                  |
| CHANNEL             |      261 Б |                 500К |        130 МБ | Канал на пользователя                                     |
| SUBSCRIPTION        |       40 Б |            60M |        2.4 ГБ | 60M подписок/сутки                                        |
| STREAM              |      242 Б |                   1M |        240 МБ | Созданий стримов/сутки                                        |
| RTMP_INGEST_SESSION |      204 Б |          1M |        204 МБ | По одной+ на стрим                                                |
| CHAT_MESSAGE        |      408 Б |                  70M |       28.5 ГБ | <=255 симв., JSON-мета                               |
| VOD_ASSET           |       84 Б |                 500К |         42 МБ | VOD создают 50% стримов                            |
| CLIP                |       96 Б |              5M |        480 МБ | 5M клипов/сутки                             |
| MEDIA_OBJECT        |      337 Б |                  11M |        3.7 ГБ | 2 на VOD (плейлист+превью) 1M/сутки + 2 на клип (видео+превью) 10M/сутки    |
| CHANNEL_COUNTERS    |       32 Б |          500К |         16 МБ | 1 запись на канал; рост = новые каналы; инкременты не увеличивают размер  |
| STREAM_COUNTERS     |       36 Б |                   1M |         36 МБ | 1 запись на стрим; рост = новые стримы; апдейты "онлайна/чата" перезаписывают |
| VOD_COUNTERS        |       40 Б |            500К |    20 МБ | 1 запись на VOD                                  |
| CLIP_COUNTERS       |       32 Б |                   5M |        160 МБ | 1 запись на клип                                     |
| SESSION             |       56 Б |         5.5M |        308 МБ | TTL 1 день; авто-очистка просроченных                                         |



TTL/накопление: VOD и чат-реплей живут до 60 дней; клипы — бессрочно. \
В хранилище из-за TTL: VOD_ASSET = 30M -> 2.5 ГБ метаданных; CHAT_MESSAGE = 408 Б -> 1.71 TB; MEDIA_OBJECT (только VOD-связанные, 2/стрим) = 60M -> 20 ГБ. Клип-объекты копятся без TTL 10M/сутки.

### QPS и консистентность
| Cущность            | Read QPS | Write QPS | Консистентность |                                    Примечания |
| ------------------- | -------: | --------: | --------------- | --------------------------------------------: |
| USER_ACCOUNT        |       60 |         6 | strong      |                                               |
| CHANNEL             |        5 |         6 | causal    |           В основном кэш 550 -> 5 (промах 1%) |
| SUBSCRIPTION        |      100 |       700 | strong   |                                               |
| STREAM              |        5 |        12 | strong   |                            Аналогично каналам |
| RTMP_INGEST_SESSION |        – |        12 | strong    |                                               |
| CHAT_MESSAGE        |       10 |       810 | causal    |                лайв в буфере; R: для VOD 1М |
| VOD_ASSET           |      0.1 |         6 | eventual  |                      R: 10 -> 0.1 (промах 1%) |
| CLIP                |        1 |        60 | causal     |                       R: 100 -> 1 (промах 1%) |
| MEDIA_OBJECT        |        2 |       120 | strong  |         W: 2 на VOD + 2 на клип; R промах 1% |
| CHANNEL_COUNTERS    |        5 |         – | eventual  |                                               |
| STREAM_COUNTERS     |        5 |         – | eventual  |                                               |
| VOD_COUNTERS        |      0.1 |         – | eventual  |                                               |
| CLIP_COUNTERS       |        1 |         – | eventual  |                                               |
| SESSION             |        5 |        64 | strong     | Чтение из кэша/JWT; БД — создание |

## 6. Физическая схема БД
<img width="2172" height="1454" alt="бд" src="https://github.com/user-attachments/assets/a75e9c07-2850-4ede-8ae5-2d4c0eca0634" />

Черный - PostgreSQL;
Фиолетовый - ScyllaDB;
Зеленый - S3;
Оранжевый - Redis;
Голубой - Clickhouse;

| название таблицы    | база данных        | шардирование и резервирование                         | балансировка запросов                       | схема резервного копирования                              |
| ------------------- | ------------------ | ----------------------------------------------------- | ------------------------------------------- | --------------------------------------------------------- |
| USER_ACCOUNT        | Postgres           | primary-replica (при падении primary одна из реплик повышается до primary)  | pgbouncer + read-only реплики              | PITR: ежедневный base + WAL в S3 (CRR)                    |
| CHANNEL            | Postgres           | primary-replica (аналогично USER_ACCOUNT)                                         | pgbouncer + read-only реплики               | PITR: ежедневный base + WAL в S3 (CRR)                |
| SUBSCRIPTION       | Postgres          | hash(channel_id); per-shard sync standby, на каждый шард есть реплики (при падении primary шарда аналогичный механизм)       | pgbouncer + read-only реплики              | PITR: ежедневный base + WAL в S3 (CRR)                    |
| STREAM             | Postgres           | range(started_at месяц) на каждый шард есть реплики (по аналогии)                            | pgbouncer + read-only реплики            | PITR: ежедневный base + WAL в S3 (CRR)                   |
| RTMP_INGEST_SESSION | Postgres           | range(created_at день); авто-TTL 1–7 д, на каждый шард есть реплики (по аналогии)                | pgbouncer                                   | PITR: ежедневный base + WAL в S3 (CRR)                    |
| CHAT_MESSAGE        | ScyllaDB           | partition(stream_id) order(offset-ms) - используется для получения сообщений в чате для VOD батчами; RF = 3;  на каждый шард есть реплики (по аналогии)               | token-aware, DC-aware round-robin           | snapshots + incremental sstables в S3                    |
| VOD_ASSET           | Postgres           | range(created_at неделя); TTL 7–60 д, на каждый шард есть реплики (по аналогии)               | pgbouncer + ro реплики                      | PITR: ежедневный base + WAL в S3 (CRR)                    |
| CLIP                | Postgres           | hash(stream_id), на каждый шард есть реплики (по аналогии)                               | pgbouncer + ro реплики                      | PITR: ежедневный base + WAL в S3 (CRR)                    |
| MEDIA_OBJECT        | Postgres + S3      | S3: versioning + CRR;                         | DB: pgbouncer + ro; Blob: CDN               | DB: PITR; S3 lifecycle 60 д -> Glacier + CRR              |
| SESSION             | Postgres           | range(expires_at день),               | pgbouncer                                   | PITR: ежедневный base + WAL в S3 (CRR)                 |
| CHANNEL_COUNTERS    | Redis              | Redis Cluster;             | client-side routing                         | RDB hourly + AOF 1s -> S3                               |
| STREAM_COUNTERS     | Redis + ClickHouse | Redis Cluster; CH: ReplicatedMT | Redis: client-side; CH: Distributed таблица | Redis: RDB/AOF -> S3; CH: clickhouse-backup в S3 ежедневно |
| VOD_COUNTERS        | Redis + ClickHouse | Redis Cluster; CH: ReplicatedMТ | Redis: client-side; CH: Distributed таблица | Redis: RDB/AOF -> S3; CH: clickhouse-backup в S3 ежедневно |
| CLIP_COUNTERS       | Redis + ClickHouse | Redis Cluster; CH: ReplicatedMT | Redis: client-side; CH: Distributed таблица | Redis: RDB/AOF -> S3; CH: clickhouse-backup в S3 ежедневно |

- Redis + ClickHouse - раз в какое-то время (например раз в час) агрегируются данные в Redis для отображения пользователям и в ClickHouse для аналитики и статистики. \
- Postgres + S3 - в PostgresSQL хранятся данные и файлы и другая необходимая информация, а в S3 сам файл. \
#### Обозначеия
- per-shard sync standby - синхронная реплика не каждый шард
- RF - количество реплик на мастер ноду
- CRR - кроссрегиональная репликация
- ReplicatedMT - ReplicatedMergeTree - репликация между репликами для Clickhouse
- token-aware, DC-aware round-robin - посылки запрсов на нужный узел и распределение по round-robin в ДЦ
- Glacier - переводим в ходное хранилище спустя 60 дней. При нехватке места можно будет удалить

### Примечание
При получении большого количества данных, например списка подписанных каналов для пользователя, неответ от небольшого количества шардов игнорируем.

### Индексы
| название таблицы                      | индексы                                                                                 |
| ------------------------------------- | --------------------------------------------------------------------------------------- |
| USER_ACCOUNT (Postgres)               | pk(id); unique(lower(email)); unique(username)                      |
| CHANNEL (Postgres)                    | pk(id); unique(user_id); unique(stream_key_hash)                        |
| SUBSCRIPTION (Postgres)               | pk(follower_id, channel_id); btree(channel_id)                  |
| STREAM (Postgres)                     | pk(id); btree(channel_id, started_at desc); partial btree(status) where status = 'live' |
| RTMP_INGEST_SESSION (Postgres)        | pk(id); btree(stream_id); partial btree(ended_at) where ended_at is null          |
| CHAT_MESSAGE (ScyllaDB)               | primary key ((stream_id), offset_ms, id)              |
| VOD_ASSET (Postgres)                  | pk(id); unique(stream_id)                            |
| CLIP (Postgres)                       | pk(id); btree(stream_id, created_at desc)                               |
| MEDIA_OBJECT (Postgres+S3)            | pk(id); unique(storage_url); btree(ttl_expires_at)                 |
| SESSION (Postgres)                    | pk(id); btree(user_id); btree(expires_at)    |
| CHANNEL_COUNTERS (Redis + ClickHouse) |  -   |
| STREAM_COUNTERS (Redis + ClickHouse)  |  -               |
| VOD_COUNTERS (Redis + ClickHouse)     |  -                                        |
| CLIP_COUNTERS (Redis + ClickHouse)    |  -                                                |


### Денормалиация
Все счетчики денормализированы по отношению к текущим данных и агрегируются раз в час

### Библиотеки
- pgx - PostgreSQL
- gocql - ScyllaDB
- go-redis - Redis
- clickhouse-go - ClickHouse
- aws-sdk-go/s3 - S3

## 7. Алгоритмы

| Алгоритм   | Область применения | Описание | 
| ---------- | -------------- | ------------ |
| Лента рекомендаций | Формирование главной страницы | Совмещение на основе коллаборативной фильтрации для получения похожих каналов для уже подписанных. Часть вычислений вынесена в офлайн этап, для быстрой подгрузки ленты стримов |
| Стриминг с сохранением VOD | Просмотр стрима пользователем в различных разрешениях, с сохранением записи | Клонирование RTMP подключений по количеству доступных разрешений и вариант с передачей чанков через CDN |

### Алгоритм рекомендаций
Мотивация - слишком долгая загрузка главной страницы для юзера

#### Используемые сущности
| Сущность | Получаемые данные |
| -------- | ----------------- |
| USER_ACCOUNT | базовые атрибуты |
| CHANNEL | базовые атрибуты |
| SUBSCRIPTION | граф подписок для коллаборативной фильтрации |
| STREAM | стримы запущенные в данный момент |

#### Кеши
| Кэш | Тип              | Описание |
| ---- | ----------------- | ----------- |
| follow:{uid}  | SET | Каналы на которые подписан пользователь, обновляем раз в 10 минут |
| live:channels | ZSET (channel_id -> base_score) | текущие каналы в лайве, где base_score = log1p(viewers), обвляется каждые 5с на основе STREAM_COUNTERS |
| entity:stream:{stream_id} | HASH | данные карточки стрима, TTL - 5 минут, инвалидация по началу, концу стрима |
| sim:channel:{channel_id} | ZSET | коэффициенты похожести, TTL - 24 часа |
| candidates:{uid} | SET | Кандидаты на рекомендаци для каждого пользователя TTL - 6 часов, рекомендации неактивных пользователей будут вытесняться из кэша |


#### Этапы алгоритма
| Этап | Описание | Количество кандидатов |
| ---- | ----------------- | ---- |
| Follow (оффлайн) | из кэша подписки пользователя | до 1000 |
| Ко-фоллоу (оффлайн) | на основе векторов, где мы можем посчитать сходимость меры Жаккара для уже подписанных с остальными каналами. Исходя из этого для каждого канала в sim:channel:{channel_id} сохраняем меру Жаккапа с другими каналами, отрезаем все каналы, где мера слишком мала | 100-1000 (на каждый канал) |
| Совмещение (офлайн) | Из прошлых двух этап собираем кандидатов | до 2000 |
| Совмещение (онлайн) | из офлайн совмещения получение каналов, которые сейчас стримят, если рекоммендаций слишком мало для новых пользователей подмешиваем из кэша live:channels самых популярных стримеров в прямом эфире | ~100 |
| Ранжирование (онлайн) | рассчет по формуле score для всех кандидатов и сортировка. е | 100 TTL 5 минут |

score = 2.5*(подписан) + 0.35*log1p(зрителей сейчас) + 1.0*(средняя мера Жаккара по подпискам пользователя и данного канала) + 0.10*(буст, если канал - партнер твича) + 0.20*(был повтор, уже показывали данные канал менее 24 часов назад) + 0.05*(совпадение языка аккаунта и стрима)


#### Возможные улучшения
- Использование эмбедингов для ускорения алгоритмов
- Использовании ML модели с учетом пользовательских действия для скоринга

### Адаптивный стриминг 

#### Вариант с ingest -> edge
Стример подключается к Ingest Node, а пользователь к Edge Node \
Этапы:
1. RTMP -> Segmenter разделение стрима на чанки HLS (с ts сегментами и m3u8 манифестами) или DASH
2. Segmenter -> Transcoder Приведение к к таргетированным разрешениям (1080p, 720p, 480p и так далее), разделение на потоки
3. Transcoder -> S3 - сохранение транскодированных чанков VOD на сервер
4. Transcoder -> RTMP (transcoded) - создание нескольких RTMP пуллов
5. RTMP (transcoded) -> RTMP (edge) - региональная RTMP node делает pull транскодированного стрима

В таком варианте пользователь просто подключается к своей региональной edge ноде с ключем стрима и выбранным разрешением.

#### Вариант с ingest -> cdn
Пользовать запрашивает манифест через CDN и по нему подгружает чанки
Этапы:
1. RTMP -> Segmenter разделение стрима на чанки HLS (с ts сегментами и m3u8 манифестами) или DASH
2. Segmenter -> Transcoder Приведение к к таргетированным разрешениям (1080p, 720p, 480p и так далее), разделение на потоки
3. Transcoder -> S3 - сохранение транскодированных чанков VOD на сервер
4. S3 -> CDN - пользователь может сразу получить чанки прочитав манифест стрима из своего CDN
5. Обновление манифестов - происходит отслеживание транскодированных сегментов и помезение в очередь, в манифесте содержатся доступные качества и URL доступных сегментов. Старые сегменты из манифеста удаляются для Live стримов.

Данный вариант снижает нагрузку на сервера RTMP, что снижает необходимость в большом количестве серверов для рестриминга контенту и передает эту нагрузку на S3 + CDN.

## 8. Технологии

| Технология | Область преминения | Мотивационная часть |
| ---------- | ------------------ | ------------------- |
| Go         | Микросервисы | Высокая производительность, низковестные потоки (горутины), сборщик мусора, статическая типизация |
| PostgreSQL | Основная база данных | ACID, поддержка репликации и шардинга. Возможность построения сложных реляционных запросов |
| NGINX | Прокси, L7 балансировка | Балансирует нагрузку между микросервисами в одном ДЦ, производит SSL-терминацию. Распределяет трафик по RTMP серверам |
| Kubernetes | Оркестрация контейнеров | Автоматизирует развертывание, управляет жизненным циклом подов и проверяет состояние сервисов |
| S3 Minio | Хранение бинарных файлов (в основном медиа) | Масштабируемое хранилище неструктурированных файлов с возможностью интеграции CDN |
| ClickHouse | База данных аналитики | Быстрая агрегация и просчет статистики по большому объему данных |
| Python | При интеграции в ИИ моделей машинного обучения для рекомендация | Большая экосистема библиотек ИИ |
| Prometheus | База данных временных рядов | Сбор метрик с микросервисов |
| Graphana | Визуализация метрик | Используется для удобного преставления метрик полученных из Prometheus |
| RTMP | Простокол передачи сообщений в реальном времени | Стриминг контента от стимера к серверу и от сервера к зрителю |
| AVC/HEVC (H.264/H.265) | Кодеки стриминга | Поддеживаются OBS и другим программным обеспечением для стриминга |
| ffmpeg | Мультимедиа фреймворк | Используется для транскодирования, декодирования и раскодирования чанков видеопотока |
| Cloudflare CDN | Глобавльная доставка контента с S3 | Уменьшения задержек, так как ноды CDN находятся по всему миру, снижение нагрузки на основной S3  |
| React.js + TypeScript | Frontend | Наиболее полулярное решение для SPA веб-приложений с большой поддержкой сообщества, большая экосистема библиотек и компонентов, реактивная архитектура |
| Kotlin, Swift | Нативные приложения под Android, IOS | Оффициальные языки для данных платформ, обеспечивающие нативную производительность и пратформозависимые фичи |
| Redis | In-memory база данных | Хранит большую часть данных в оперативной памяти, что позволяет быстро раздавать кэшированние данные, снижает нагрузки на основную PostgreSQL базу данных |
| gRPC | Протокол общения между микросервисами | Снижение трафика, так как данные передаются в бинарном виде, представление интерфейса для микросервисов в виде удаленных процедур |
| RabbitMQ | Брокер сообщений | Позволяет настроить очередь ассинхронных запросов между микросервисами для снижения нагрузки |
| ScyllaDB | База данных для истории чата | Позволяет быстро получить отсортированные батчи |

## 9. Обеспечение надёжности
### Резервирование
| Вид резирвирования | Описание | Схема резервирования |
| ------------------ | -------- | -------------------- |
| Резервирование ресурсов (CPU, RAM) | Дополнительные сервера, который смогут принять нагрузку в пиковых сценариях | 1.5-2х от базовых |
| Резервирование физических компонентов (сервера, диски и т.п.) | Дополнительное оборудование для замены в случае отказа основного | 2х от базовых |
| Резервирование ДЦ | Распределение нагрузки между датацентрами с синхронизацией данных | Active/Active схема, независимые источники питания |
| Резервирование БД | Репликация  | Active/Passive схема, где readonly реплика повышается до Active при падении основной, реплик минимум 2х от основного |
| Резерирование логики | Кэширование частых запросах на промежуточных CDN для снижения нагрузки и частичной работы сервиса при падении основного | Независимость кэша от основного сервиса |

### Сегменирование
- Критические и тяжелые сервисы (авторизация, рекомендации) выделяются в отдельные сервисы с отдельными кластерами серверов
- Разделение тяжелых сервисов (рекомендации) на подсервисы (например, offline и online рекомендации)
- Отдельная группа серверов для развертки тестовых версий и A/B тестов
- Независимость мониторинга от сервисов

### Graceful Shutdown
- Ожидание завершения запросов всех пользователей
- Для долгих сессий/запросов вернуть ошибку с информацией о плановом отключении
- Алерты о корректном завершнении
- Отклонение новых запросов

### Graceful Degradation
- Переход на упрошенную логику (например, в сервисе рекомендаций отключение ИИ-модуля и переход на коллаборативную фильтрацию)
- Выключение отказавших некритичных модулей (например, при отказе транскодера передаем всем пользователям видео в одном и том же разрешении, отключается чат, счетчик количества зрителей и так далее; важнее, чтобы работал критический функционал)
- При полном отказе рекомендаций берем самых популярных, а в случае отказа и их случайных.

### Асинхронные паттерны
- CQRS для разделения записи и чтения, так как количество запросов на эти действия отличаются на порядок. При использовании паттерна проще масштабировать нагрузку
- Отбивка статистика: при выполнении запросов, которые содержат статистические данные, параллельно помещаем эти действия в брокер сообщений RabbitMQ и далее в ClickHouse. Так собирается аналитика для дашбордов и внутреннего анализа

### Observability
#### Логирование + Трейсинг
- Разные типы логов: access, error, work
- Сбор в ClickHouse/ElasticSearch черезе Logstash
- Семплирование по request_id для избежания перегрузки
- Поддержка трейсинга по всем сервисам по объединенному request_id
#### Метрики + Алерты
- Системные: CPU, RAM, загруженность диска и т.д.
- Бизнесовые: RPS, latency, error rate и т.д.
- Собирается в дашборды Graphana
- При превышение заданных приделов latency > N или error rate > N посылать алерт об ошибках
- Обновление данных о доступности сервисов на status page, для того, чтобы пользователи могли понять, когда сервис упал

   





## Список источников
[^1]: https://help.twitch.tv/s/article/video-on-demand 
[^2]: https://resourcera.com/data/social/twitch-statistics/
[^3]: https://twitchtracker.com/
[^4]: https://www.demandsage.com/twitch-users/
[^5]: https://analyzify.com/statsup/twitch#user-audience
[^6]: https://www.statista.com/statistics/511558/twitch-traffic-by-country/
[^7]: https://twitchinsights.net/accounts
[^8]: https://stats.streamelements.com/c/global
[^9]: https://help.twitch.tv/s/article/guide-to-custom-messages?language=ru
[^10]: https://help.twitch.tv/s/article/moments?language=ru
[^11]: https://blog.nginx.org/blog/testing-the-performance-of-nginx-and-nginx-plus-web-servers
